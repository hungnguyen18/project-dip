import streamlit as st
import numpy as np
import cv2 as cv
import os
from datetime import datetime
from PIL import Image
import time
import joblib
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Helper functions
def create_folder(folder_name):
    if not os.path.exists(folder_name):
        os.makedirs(folder_name)

def save_face_images(folder_name, cap):
    count = 0
    progress = st.progress(0)
    saved_images = []
    while count < 150:
        ret, frame = cap.read()
        if not ret:
            st.write("Kh√¥ng th·ªÉ ch·ª•p khung h√¨nh")
            break
        faces = face_cascade.detectMultiScale(frame, 1.1, 4)
        for (x, y, w, h) in faces:
            count += 1
            face_img = frame[y:y + h, x:x + w]
            img_name = f"{folder_name}/{str(count)}.jpg"
            cv.imwrite(img_name, face_img)
            saved_images.append(img_name)
            progress.progress(int((count / 150) * 100))
        if count >= 150:
            break
    cap.release()
    return saved_images

class IdentityMetadata():
    def __init__(self, base, name, file):
        self.base = base
        self.name = name
        self.file = file

    def __repr__(self):
        return self.image_path()

    def image_path(self):
        return os.path.join(self.base, self.name, self.file) 

def load_metadata(path):
    metadata = []
    for i in sorted(os.listdir(path)):
        for f in sorted(os.listdir(os.path.join(path, i))):
            ext = os.path.splitext(f)[1]
            if ext in ['.jpg', '.jpeg', '.bmp']:
                metadata.append(IdentityMetadata(path, i, f))
    return np.array(metadata)

# Helper functions
def str2bool(v):
    if v.lower() in ['on', 'yes', 'true', 'y', 't']:
        return True
    elif v.lower() in ['off', 'no', 'false', 'n', 'f']:
        return False
    else:
        raise NotImplementedError

def visualize(input, faces, fps, thickness=2):
    if faces[1] is not None:
        for idx, face in enumerate(faces[1]):
            coords = face[:-1].astype(np.int32)
            cv.rectangle(input, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), (0, 255, 0), thickness)
            cv.circle(input, (coords[4], coords[5]), 2, (255, 0, 0), thickness)
            cv.circle(input, (coords[6], coords[7]), 2, (0, 0, 255), thickness)
            cv.circle(input, (coords[8], coords[9]), 2, (0, 255, 0), thickness)
            cv.circle(input, (coords[10], coords[11]), 2, (255, 0, 255), thickness)
            cv.circle(input, (coords[12], coords[13]), 2, (0, 255, 255), thickness)
    cv.putText(input, 'FPS: {:.2f}'.format(fps), (1, 16), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# Streamlit UI for Face Detection
st.title('ü§¶ ·ª®ng d·ª•ng Nh·∫≠n di·ªán Khu√¥n m·∫∑t')
st.write("·ª®ng d·ª•ng n√†y gi√∫p b·∫°n thu th·∫≠p, hu·∫•n luy·ªán v√† nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ camera theo th·ªùi gian th·ª±c. B·∫°n c√≥ th·ªÉ thu th·∫≠p h√¨nh ·∫£nh khu√¥n m·∫∑t ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh v√† sau ƒë√≥ s·ª≠ d·ª•ng m√¥ h√¨nh n√†y ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t.")

st.sidebar.title("ƒêi·ªÅu h∆∞·ªõng")
st.sidebar.write("·ª®ng d·ª•ng n√†y gi√∫p b·∫°n thu th·∫≠p, hu·∫•n luy·ªán v√† nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ camera theo th·ªùi gian th·ª±c. B·∫°n c√≥ th·ªÉ thu th·∫≠p h√¨nh ·∫£nh khu√¥n m·∫∑t ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh v√† sau ƒë√≥ s·ª≠ d·ª•ng m√¥ h√¨nh n√†y ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t.")
choice = st.sidebar.selectbox("Ch·ªçn h√†nh ƒë·ªông", ["Hu·∫•n luy·ªán", "Nh·∫≠n di·ªán khu√¥n m·∫∑t", "Xem Khu√¥n m·∫∑t ƒë√£ L∆∞u"])

def train_model(metadata):
    if len(set(m.name for m in metadata)) < 2:
        st.error("C·∫ßn √≠t nh·∫•t hai ng∆∞·ªùi kh√°c nhau ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
        return

    recognizer = cv.FaceRecognizerSF.create(
        "./models/face_recognition_sface_2021dec.onnx", "")

    embedded = np.zeros((metadata.shape[0], 128))
    progress = st.progress(0)

    for i, m in enumerate(metadata):
        img = cv.imread(m.image_path(), cv.IMREAD_COLOR)
        face_feature = recognizer.feature(img)
        embedded[i] = face_feature
        progress.progress(int((i / len(metadata)) * 100))

    targets = np.array([m.name for m in metadata])
    encoder = LabelEncoder()
    encoder.fit(targets)

    y = encoder.transform(targets)

    train_idx = np.arange(metadata.shape[0]) % 5 != 0
    test_idx = np.arange(metadata.shape[0]) % 5 == 0
    X_train = embedded[train_idx]
    X_test = embedded[test_idx]
    y_train = y[train_idx]
    y_test = y[test_idx]

    svc = SVC(probability=True)  # Using SVC with probability estimation
    svc.fit(X_train, y_train)
    acc_svc = accuracy_score(y_test, svc.predict(X_test))
    st.write(f'ƒê·ªô ch√≠nh x√°c c·ªßa SVM: {acc_svc:.6f}')
    joblib.dump(svc, './models/svc.pkl')
    joblib.dump(encoder, './models/label_encoder.pkl')
    st.success("Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t v√† ƒë√£ l∆∞u.")

face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Sidebar sections
if choice == "Hu·∫•n luy·ªán":
    st.sidebar.header("Ch·∫ø ƒë·ªô Hu·∫•n luy·ªán")
    st.header("Ch·∫ø ƒë·ªô Hu·∫•n luy·ªán")
    st.write("""
        ### H∆∞·ªõng d·∫´n:
        1. Nh·∫•n **B·∫Øt ƒë·∫ßu Camera** ƒë·ªÉ b·∫Øt ƒë·∫ßu ch·ª•p h√¨nh ·∫£nh.
        2. Khi camera ƒëang ch·∫°y, nh·∫•n **L∆∞u** v√† nh·∫≠p t√™n ƒë·ªÉ l∆∞u h√¨nh ·∫£nh khu√¥n m·∫∑t.
        3. H√¨nh ·∫£nh khu√¥n m·∫∑t s·∫Ω ƒë∆∞·ª£c l∆∞u v√† hi·ªÉn th·ªã b√™n d∆∞·ªõi.
    """)

    if 'cap' not in st.session_state:
        st.session_state.cap = None

    if st.session_state.cap is None or not st.session_state.cap.isOpened():
        start_button = st.sidebar.button("B·∫Øt ƒë·∫ßu Camera")
    else:
        start_button = None
    
    if start_button:
        st.session_state.cap = cv.VideoCapture(0)
        st.session_state.start = True

    if 'start' in st.session_state and st.session_state.start:
        FRAME_WINDOW = st.image([])
        stop_button = st.sidebar.button("D·ª´ng Camera")
        save_button = st.sidebar.button("L∆∞u")

        if stop_button:
            st.session_state.cap.release()
            st.session_state.start = False

        prev_time = 0

        while st.session_state.start:
            curr_time = time.time()
            ret, frame = st.session_state.cap.read()
            if not ret:
                st.write("Kh√¥ng th·ªÉ ch·ª•p khung h√¨nh")
                break
            faces = face_cascade.detectMultiScale(frame, 1.1, 4)
            for (x, y, w, h) in faces:
                cv.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            
            fps = 1 / (curr_time - prev_time)
            prev_time = curr_time
            cv.putText(frame, f"FPS: {int(fps)}", (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
            FRAME_WINDOW.image(frame, channels="BGR")

            if save_button:
                name = st.text_input("Nh·∫≠p t√™n cho khu√¥n m·∫∑t", key='name_input')
                if name:
                    folder_name = f"./data/faces/{name}"
                    create_folder(folder_name)
                    
                    with st.spinner('ƒêang l∆∞u h√¨nh ·∫£nh...'):
                        saved_images = save_face_images(folder_name, st.session_state.cap)
                        st.balloons()  # Show visual feedback for success
                        st.success(f"ƒê√£ l∆∞u 150 h√¨nh ·∫£nh v√†o {folder_name}")
                        st.write(f"ƒê√£ l∆∞u h√¨nh ·∫£nh cho {name}")

                        # Display saved images with timestamp
                        st.header(f"H√¨nh ·∫£nh cho {name}")
                        col1, col2, col3, col4, col5 = st.columns(5)
                        cols = [col1, col2, col3, col4, col5]
                        for idx, img_path in enumerate(saved_images):
                            img = Image.open(img_path)
                            cols[idx % 5].image(img, caption=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

if choice == "Nh·∫≠n di·ªán khu√¥n m·∫∑t":
    st.sidebar.header("Ch·∫ø ƒë·ªô Nh·∫≠n di·ªán")
    st.header("Ch·∫ø ƒë·ªô Nh·∫≠n di·ªán")
    st.write("""
        ### H∆∞·ªõng d·∫´n:
        1. ƒê·∫£m b·∫£o r·∫±ng c√°c m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u tr∆∞·ªõc ƒë√≥.
        2. Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh ph√°t hi·ªán v√† nh·∫≠n di·ªán khu√¥n m·∫∑t.
        3. ƒêi·ªÅu ch·ªânh c√°c th√¥ng s·ªë nh∆∞ ng∆∞·ª°ng ƒëi·ªÉm, ng∆∞·ª°ng NMS, v√† Top K.
        4. Nh·∫•n **B·∫Øt ƒë·∫ßu Nh·∫≠n di·ªán** ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t theo th·ªùi gian th·ª±c.
    """)

    # Load models and label dictionary
    svc = joblib.load('./models/svc.pkl')
    encoder = joblib.load('./models/label_encoder.pkl')

    face_detection_model_path = st.text_input('ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh ph√°t hi·ªán khu√¥n m·∫∑t', './models/face_detection_yunet_2023mar.onnx')
    face_recognition_model_path = st.text_input('ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t', './models/face_recognition_sface_2021dec.onnx')
    score_threshold = st.slider('Ng∆∞·ª°ng ƒêi·ªÉm', 0.0, 1.0, 0.9)
    nms_threshold = st.slider('Ng∆∞·ª°ng NMS', 0.0, 1.0, 0.3)
    top_k = st.number_input('Top K', min_value=1, value=5000)
    
    if st.button('B·∫Øt ƒë·∫ßu Nh·∫≠n di·ªán'):
        cap = cv.VideoCapture(0)
        frameWidth = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))
        frameHeight = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))
        
        detector = cv.FaceDetectorYN.create(
            face_detection_model_path,
            "",
            (frameWidth, frameHeight),  # Update input size
            score_threshold,
            nms_threshold,
            top_k
        )
        recognizer = cv.FaceRecognizerSF.create(face_recognition_model_path, "")
        tm = cv.TickMeter()

        FRAME_WINDOW = st.image([])
        stop_detection = st.button('D·ª´ng Nh·∫≠n di·ªán')
        while cap.isOpened():
            hasFrame, frame = cap.read()
            if not hasFrame:
                st.write('Kh√¥ng c√≥ khung h√¨nh n√†o!')
                break

            detector.setInputSize((frameWidth, frameHeight))  # Ensure the input size is set correctly
            
            tm.start()
            faces = detector.detect(frame)
            tm.stop()

            if faces[1] is not None:
                for face in faces[1]:
                    face_align = recognizer.alignCrop(frame, face)
                    face_feature = recognizer.feature(face_align)
                    test_predict = svc.predict(face_feature)
                    test_proba = svc.predict_proba(face_feature)
                    if max(test_proba[0]) > 0.6:  # Threshold for recognizing the face
                        result = encoder.inverse_transform(test_predict)[0]
                        coords = face[:-1].astype(np.int32)
                        cv.putText(frame, result, (coords[0], coords[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                        cv.rectangle(frame, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), (0, 255, 0), 2)
                    else:
                        coords = face[:-1].astype(np.int32)
                        cv.putText(frame, 'Kh√¥ng r√µ', (coords[0], coords[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
                        cv.rectangle(frame, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), (0, 0, 255), 2)

            visualize(frame, faces, tm.getFPS())
            FRAME_WINDOW.image(frame, channels="BGR")

            if stop_detection:
                break

        cap.release()
        cv.destroyAllWindows()

if choice == "Xem Khu√¥n m·∫∑t ƒë√£ L∆∞u":
    st.sidebar.header("Xem Khu√¥n m·∫∑t ƒë√£ L∆∞u")
    st.header("Xem Khu√¥n m·∫∑t ƒë√£ L∆∞u")
    st.write("""
        ### H∆∞·ªõng d·∫´n:
        1. Ch·ªçn t√™n t·ª´ danh s√°ch ƒë·ªÉ xem c√°c h√¨nh ·∫£nh ƒë√£ l∆∞u cho khu√¥n m·∫∑t ƒë√≥.
        2. C√°c h√¨nh ·∫£nh s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã b√™n d∆∞·ªõi.
    """)

    if os.path.exists('./data/faces'):
        face_folders = os.listdir('./data/faces')
        selected_face = st.sidebar.selectbox("Ch·ªçn khu√¥n m·∫∑t ƒë·ªÉ xem h√¨nh ·∫£nh", face_folders)

        if selected_face:
            folder_path = f"./data/faces/{selected_face}"
            st.header(f"H√¨nh ·∫£nh cho {selected_face}")
            col1, col2, col3, col4, col5 = st.columns(5)
            cols = [col1, col2, col3, col4, col5]
            for idx, img in enumerate(os.listdir(folder_path)):
                img_path = os.path.join(folder_path, img)
                img = Image.open(img_path)
                cols[idx % 5].image(img, caption=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    else:
        st.write("Ch∆∞a c√≥ khu√¥n m·∫∑t n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán.")
